{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zZuRLEl28ta"
   },
   "source": [
    "# Data preparation, modeling and classification\n",
    "\n",
    "Run this notebook in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhHr98akusgT"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gsubpfNvlMH"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pikp4bowvbSa"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIZnoWWBKc3T"
   },
   "outputs": [],
   "source": [
    "# set seed\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfME-_tZwdkR"
   },
   "source": [
    "### Authentifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18063,
     "status": "ok",
     "timestamp": 1656266606718,
     "user": {
      "displayName": "Alexander Merdian-Tarko",
      "userId": "02819705391358537583"
     },
     "user_tz": -120
    },
    "id": "UibE9glKweLB",
    "outputId": "79f06508-b2dc-442e-bd60-2a394daddf4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# mount drive if not already mounted\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEcnf8Acvh6l"
   },
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozMdLf-EpAPu"
   },
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = 'farm_plot_detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aL-vV7vCpn8t"
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE_PREFIX = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuT-YKOXptAz"
   },
   "outputs": [],
   "source": [
    "TEST_FILE_PREFIX = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCRz6I9kpua1"
   },
   "outputs": [],
   "source": [
    "FILE_EXTENSION = '.tfrecord.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9DfAq_MOpwkj"
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE_PATH = 'drive/MyDrive/' + OUTPUT_FOLDER + '/' + TRAIN_FILE_PREFIX + FILE_EXTENSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFsbfItKp4jx"
   },
   "outputs": [],
   "source": [
    "TEST_FILE_PATH = 'drive/MyDrive/' + OUTPUT_FOLDER + '/' + TEST_FILE_PREFIX + FILE_EXTENSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUpFplLhpPoX"
   },
   "outputs": [],
   "source": [
    "BANDS = ['B2', 'B3', 'B4', 'B8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i00fXEXppfUt"
   },
   "outputs": [],
   "source": [
    "LABEL = 'landcover'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPRvNzCJxFzj"
   },
   "outputs": [],
   "source": [
    "N_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zm8n7TlVpjQg"
   },
   "outputs": [],
   "source": [
    "FEATURE_NAMES = list(BANDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ufoa5zypno6"
   },
   "outputs": [],
   "source": [
    "FEATURE_NAMES.append(LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TU37trNZyCi2"
   },
   "outputs": [],
   "source": [
    "IMAGE_FILE_PREFIX = 'image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RreOmkANzA4o"
   },
   "outputs": [],
   "source": [
    "OUTPUT_IMAGE_FILE = 'drive/MyDrive/' + OUTPUT_FOLDER + '/classified_image.TFRecord'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7m9Dk7EvnQE"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zwYgX5OkudMz"
   },
   "outputs": [],
   "source": [
    "def parse_tfrecord(example_proto):\n",
    "\n",
    "  \"\"\"The parsing function.\n",
    "\n",
    "  Read a serialized example into the structure defined by featuresDict.\n",
    "\n",
    "  Args:\n",
    "    example_proto: a serialized Example.\n",
    "\n",
    "  Returns:\n",
    "    A tuple of the predictors dictionary and the label, cast to an `int32`.\n",
    "  \"\"\"\n",
    "\n",
    "  parsed_features = tf.io.parse_single_example(example_proto, features_dict)\n",
    "  labels = parsed_features.pop(LABEL)\n",
    "\n",
    "  return parsed_features, tf.cast(labels, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtliEgWWum8M"
   },
   "outputs": [],
   "source": [
    "def normalized_difference(a, b):\n",
    "\n",
    "  \"\"\"Compute normalized difference of two inputs.\n",
    "\n",
    "  Compute (a - b) / (a + b).  If the denomenator is zero, add a small delta.\n",
    "\n",
    "  Args:\n",
    "    a: an input tensor with shape=[1]\n",
    "    b: an input tensor with shape=[1]\n",
    "\n",
    "  Returns:\n",
    "    The normalized difference as a tensor.\n",
    "  \"\"\"\n",
    "\n",
    "  nd = (a - b) / (a + b)\n",
    "  nd_inf = (a - b) / (a + b + 0.000001)\n",
    "\n",
    "  return tf.where(tf.math.is_finite(nd), nd, nd_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mllIg6KriGtq"
   },
   "outputs": [],
   "source": [
    "def add_ndvi(features, label):\n",
    "\n",
    "  \"\"\"Add NDVI to the dataset.\n",
    "  Args:\n",
    "    features: a dictionary of input tensors keyed by feature name.\n",
    "    label: the target label\n",
    "\n",
    "  Returns:\n",
    "    A tuple of the input dictionary with an NDVI tensor added and the label.\n",
    "  \"\"\"\n",
    "\n",
    "  features['NDVI'] = normalized_difference(features['B8'], features['B4'])\n",
    "  \n",
    "  return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2EDbFA1biJNN"
   },
   "outputs": [],
   "source": [
    "# Keras requires inputs as a tuple\n",
    "# note that inputs must be in the right shape\n",
    "# also note that to use categorical_crossentropy loss the label needs to be turned into a one-hot vector\n",
    "def to_tuple(inputs, label):\n",
    "  return (tf.transpose(list(inputs.values())),\n",
    "          tf.one_hot(indices=label, depth=N_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TCbKicujpED"
   },
   "outputs": [],
   "source": [
    "# parsing function\n",
    "def parse_image(example_proto):\n",
    "  return tf.io.parse_single_example(example_proto, image_features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XR99olph20Op"
   },
   "source": [
    "## Prepare and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OEEmDGBhtvXr"
   },
   "outputs": [],
   "source": [
    "# create dataset from TFRecord file\n",
    "train_dataset = tf.data.TFRecordDataset(TRAIN_FILE_PATH, compression_type='GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5kVMs9kuT2C"
   },
   "outputs": [],
   "source": [
    "# list of fixed-length features, all of which are float32\n",
    "columns = [tf.io.FixedLenFeature(shape=[1], dtype=tf.float32) for k in FEATURE_NAMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1656266607151,
     "user": {
      "displayName": "Alexander Merdian-Tarko",
      "userId": "02819705391358537583"
     },
     "user_tz": -120
    },
    "id": "uMM75AeJh5Dz",
    "outputId": "9afa84c5-f63b-4209-dfff-16b7d1611543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B2': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
      " 'B3': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
      " 'B4': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
      " 'B8': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
      " 'landcover': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None)}\n"
     ]
    }
   ],
   "source": [
    "# dictionary with names as keys, features as values\n",
    "features_dict = dict(zip(FEATURE_NAMES, columns))\n",
    "pprint(features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 411,
     "status": "ok",
     "timestamp": 1656266607539,
     "user": {
      "displayName": "Alexander Merdian-Tarko",
      "userId": "02819705391358537583"
     },
     "user_tz": -120
    },
    "id": "oANL_6cciA0d",
    "outputId": "51506528-aa33-4290-b3eb-afaf6fb87a47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'B2': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03195], dtype=float32)>,\n",
      "  'B3': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.05305], dtype=float32)>,\n",
      "  'B4': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03505], dtype=float32)>,\n",
      "  'B8': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.2423], dtype=float32)>},\n",
      " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "# map function over dataset\n",
    "parsed_dataset = train_dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
    "pprint(iter(parsed_dataset).next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TS7Ud18iJS5"
   },
   "outputs": [],
   "source": [
    "# add NDVI to dataset\n",
    "input_dataset = parsed_dataset.map(add_ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-d8Pi4l8iJGT"
   },
   "outputs": [],
   "source": [
    "# map to_tuple function, shuffle and batch\n",
    "input_dataset = input_dataset.map(to_tuple).batch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYQ21I3z264W"
   },
   "source": [
    "## Setup and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEDbAdlIij0w"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dropout(0.2),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dropout(0.2),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dropout(0.2),\n",
    "                                    tf.keras.layers.Dense(N_CLASSES, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xr5CuCVqijxs"
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2830,
     "status": "ok",
     "timestamp": 1656266610587,
     "user": {
      "displayName": "Alexander Merdian-Tarko",
      "userId": "02819705391358537583"
     },
     "user_tz": -120
    },
    "id": "PQVunG9nuwla",
    "outputId": "4ac8bdb0-7e1f-4426-c852-2db2c4e82742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 49ms/step - loss: 1.1292 - accuracy: 0.1613\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.0739 - accuracy: 0.5484\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.0375 - accuracy: 0.6613\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.9989 - accuracy: 0.7903\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.9706 - accuracy: 0.7419\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.9196 - accuracy: 0.7903\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.8240 - accuracy: 0.8548\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7394 - accuracy: 0.8710\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.8871\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.8387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc12333490>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "\n",
    "model.fit(x=input_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1656266611454,
     "user": {
      "displayName": "Alexander Merdian-Tarko",
      "userId": "02819705391358537583"
     },
     "user_tz": -120
    },
    "id": "xRl51FAou8X2",
    "outputId": "d42bb479-d1db-49a4-afe4-746d3ffd14ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 2ms/step - loss: 0.4938 - accuracy: 0.9643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.49376755952835083, 0.9642857313156128]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model in test dataset\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.TFRecordDataset(TEST_FILE_PATH, compression_type='GZIP')\n",
    "    .map(parse_tfrecord, num_parallel_calls=5)\n",
    "    .map(add_ndvi)\n",
    "    .map(to_tuple)\n",
    "    .batch(1)\n",
    "    )\n",
    "\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrhaVzaO3A11"
   },
   "source": [
    "## Classify image from Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F28kNIbMi2MD"
   },
   "outputs": [],
   "source": [
    "# get list of all files in output folder\n",
    "files_list = os.listdir('drive/MyDrive/' + OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHaiH7m5i4cq"
   },
   "outputs": [],
   "source": [
    "# get only files generated by image export\n",
    "exported_files_list = [s for s in files_list if IMAGE_FILE_PREFIX in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxT6gcV0i9G1"
   },
   "outputs": [],
   "source": [
    "# get list of image files and JSON mixer file\n",
    "\n",
    "image_files_list = []\n",
    "json_file = None\n",
    "\n",
    "for f in exported_files_list:\n",
    "  if f.endswith('.tfrecord.gz'):\n",
    "    image_files_list.append(f)\n",
    "  elif f.endswith('.json'):\n",
    "    json_file = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1656266611457,
     "user": {
      "displayName": "Alexander Merdian-Tarko",
      "userId": "02819705391358537583"
     },
     "user_tz": -120
    },
    "id": "Pm6qA9NZu_3d",
    "outputId": "6acf9eeb-d36c-4649-db64-3c5a822dae42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image-00000.tfrecord.gz']\n",
      "image-mixer.json\n",
      "drive/MyDrive/farm_plots/image-mixer.json\n"
     ]
    }
   ],
   "source": [
    "# make sure files are in right order\n",
    "image_files_list.sort()\n",
    "json_file_path = 'drive/MyDrive/' + OUTPUT_FOLDER + '/' + 'image-mixer.json'\n",
    "pprint(image_files_list)\n",
    "print(json_file)\n",
    "print(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7F2TEFDjQLc"
   },
   "outputs": [],
   "source": [
    "# load contents of mixer file to JSON object\n",
    "json_text = !cat {json_file_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1656266611462,
     "user": {
      "displayName": "Alexander Merdian-Tarko",
      "userId": "02819705391358537583"
     },
     "user_tz": -120
    },
    "id": "6RRKO_JMvo6b",
    "outputId": "3f44f48e-15be-4619-a6e8-0f946fed4c59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patchDimensions': [256, 256],\n",
      " 'patchesPerRow': 6,\n",
      " 'projection': {'affine': {'doubleMatrix': [8.983152841195215e-05,\n",
      "                                            0.0,\n",
      "                                            23.493010804878963,\n",
      "                                            0.0,\n",
      "                                            -8.983152841195215e-05,\n",
      "                                            -16.639853333859545]},\n",
      "                'crs': 'EPSG:4326'},\n",
      " 'totalPatches': 12}\n"
     ]
    }
   ],
   "source": [
    "# get single string w/ newlines from IPython.utils.text.SList\n",
    "mixer = json.loads(json_text.nlstr)\n",
    "pprint(mixer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-gCX1n3Vy34D"
   },
   "outputs": [],
   "source": [
    "image_files_list_path = ['drive/MyDrive/' + OUTPUT_FOLDER + '/' + i for i in image_files_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7qXztccjcUm"
   },
   "outputs": [],
   "source": [
    "# get relevant info from JSON mixer file\n",
    "patch_width = mixer['patchDimensions'][0]\n",
    "patch_height = mixer['patchDimensions'][1]\n",
    "patches = mixer['totalPatches']\n",
    "patch_dimensions_flat = [patch_width * patch_height, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4YROxZAjec4"
   },
   "outputs": [],
   "source": [
    "# note that tensors are in the shape of a patch, one patch for each band\n",
    "image_columns = [tf.io.FixedLenFeature(shape=patch_dimensions_flat, dtype=tf.float32) for k in BANDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOMD0RzAjeaK"
   },
   "outputs": [],
   "source": [
    "# parsing dictionary\n",
    "image_features_dict = dict(zip(BANDS, image_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPzGMbyKjeXa"
   },
   "outputs": [],
   "source": [
    "# note that you can make one dataset from many files by specifying a list\n",
    "image_dataset = tf.data.TFRecordDataset(image_files_list_path, compression_type='GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zq3WHS-6jpAp"
   },
   "outputs": [],
   "source": [
    "# parse data into tensors, one long tensor per patch\n",
    "image_dataset = image_dataset.map(parse_image, num_parallel_calls=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nM1QmZ2wjxsK"
   },
   "outputs": [],
   "source": [
    "# break our long tensors into many little ones\n",
    "image_dataset = image_dataset.flat_map(lambda features: tf.data.Dataset.from_tensor_slices(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BXAEft7jxoz"
   },
   "outputs": [],
   "source": [
    "# add additional features (NDVI), including features that don't have a label\n",
    "image_dataset = image_dataset.map(lambda features: add_ndvi(features, None)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9Lrgh1zjxl-"
   },
   "outputs": [],
   "source": [
    "# turn dictionary in each record into a tuple without a label\n",
    "image_dataset = image_dataset.map(lambda data_dict: (tf.transpose(list(data_dict.values())), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YrechDIvsFC"
   },
   "outputs": [],
   "source": [
    "# turn each patch into a batch\n",
    "image_dataset = image_dataset.batch(patch_width * patch_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42519,
     "status": "ok",
     "timestamp": 1656266654253,
     "user": {
      "displayName": "Alexander Merdian-Tarko",
      "userId": "02819705391358537583"
     },
     "user_tz": -120
    },
    "id": "YyR_Yv_eyKCN",
    "outputId": "b965f261-1f9d-49ba-b11f-fd84d1d08323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 42s 3s/step\n"
     ]
    }
   ],
   "source": [
    "# run prediction in batches, with as many steps as there are patches\n",
    "predictions = model.predict(image_dataset, steps=patches, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1656266654255,
     "user": {
      "displayName": "Alexander Merdian-Tarko",
      "userId": "02819705391358537583"
     },
     "user_tz": -120
    },
    "id": "M41mc3Ipx2iO",
    "outputId": "93c4865c-c0ae-4a7e-8b93-9526cd7e9931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51863724 0.04946535 0.43189737]]\n"
     ]
    }
   ],
   "source": [
    "# note that predictions come as a numpy array\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dc9DUpp7zJcq"
   },
   "source": [
    "## Write classified image to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1656266654257,
     "user": {
      "displayName": "Alexander Merdian-Tarko",
      "userId": "02819705391358537583"
     },
     "user_tz": -120
    },
    "id": "Etg9gsMAyBQQ",
    "outputId": "bc355d28-b771-48e3-aa25-9e268edfef0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file drive/MyDrive/farm_plots/classified_image.TFRecord\n"
     ]
    }
   ],
   "source": [
    "print('Writing to file ' + OUTPUT_IMAGE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwcwetoqkKKj"
   },
   "outputs": [],
   "source": [
    "# instantiate writer\n",
    "writer = tf.io.TFRecordWriter(OUTPUT_IMAGE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34817,
     "status": "ok",
     "timestamp": 1656266689061,
     "user": {
      "displayName": "Alexander Merdian-Tarko",
      "userId": "02819705391358537583"
     },
     "user_tz": -120
    },
    "id": "jYWULWr1z_Zl",
    "outputId": "6734c1ee-b80b-4a7e-fb1f-023929a171ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with patch 1 of 12...\n",
      "Done with patch 2 of 12...\n",
      "Done with patch 3 of 12...\n",
      "Done with patch 4 of 12...\n",
      "Done with patch 5 of 12...\n",
      "Done with patch 6 of 12...\n",
      "Done with patch 7 of 12...\n",
      "Done with patch 8 of 12...\n",
      "Done with patch 9 of 12...\n",
      "Done with patch 10 of 12...\n",
      "Done with patch 11 of 12...\n",
      "Done with patch 12 of 12...\n"
     ]
    }
   ],
   "source": [
    "# every patch-worth of predictions we'll dump an example into the output file with a single feature that holds our predictions\n",
    "# since our predictions are already in the order of the exported data, the patches we create here will also be in the right order\n",
    "\n",
    "patch = [[], [], [], []]\n",
    "\n",
    "cur_patch = 1\n",
    "\n",
    "for prediction in predictions:\n",
    "\n",
    "  patch[0].append(tf.argmax(prediction, 1))\n",
    "  patch[1].append(prediction[0][0])\n",
    "  patch[2].append(prediction[0][1])\n",
    "  patch[3].append(prediction[0][2])\n",
    "\n",
    "  # once we've seen a patches-worth of class_ids...\n",
    "\n",
    "  if (len(patch[0]) == patch_width * patch_height):\n",
    "    print('Done with patch ' + str(cur_patch) + ' of ' + str(patches) + '...')\n",
    "\n",
    "    # create an example\n",
    "\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={                \n",
    "                'prediction': tf.train.Feature(                    \n",
    "                    int64_list=tf.train.Int64List(\n",
    "                        value=patch[0])),                     \n",
    "                     'vegetation': tf.train.Feature(\n",
    "                         float_list=tf.train.FloatList(\n",
    "                             value=patch[1])),\n",
    "                     'water': tf.train.Feature(\n",
    "                         float_list=tf.train.FloatList(\n",
    "                             value=patch[2])),\n",
    "                     'farm_plots': tf.train.Feature(\n",
    "                         float_list=tf.train.FloatList(\n",
    "                             value=patch[3])),\n",
    "                     }\n",
    "                     )\n",
    "        )\n",
    "    \n",
    "    # write the example to the file and clear our patch array so it's ready for another batch of class ids\n",
    "\n",
    "    writer.write(example.SerializeToString())\n",
    "    patch = [[], [], [], []]\n",
    "    cur_patch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2CdCZUSktki"
   },
   "outputs": [],
   "source": [
    "# close writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jskxdpDo3O5g"
   },
   "source": [
    "## Upload classified image to Earth Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsXrZ9L3wGlP"
   },
   "source": [
    "Uploads via the command line only work with Cloud Storage, not with Drive. Thus, the classified image in TFRecord format with the respecive mixer file in JSON format need to be uploaded to Earth Engine manually."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN2U4D4N6Nxob/ykv/5EPph",
   "collapsed_sections": [],
   "mount_file_id": "1R3QAUTKxURaEdwhReaQeoEEvCKHJblu0",
   "name": "02_data_preparation_modeling_and_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
